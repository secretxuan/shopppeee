# æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ Shoppee ç”µå•†ç³»ç»Ÿçš„æ€§èƒ½ä¼˜åŒ–ç­–ç•¥å’Œæœ€ä½³å®è·µã€‚

## ğŸ¯ æ€§èƒ½ç›®æ ‡

- **å“åº”æ—¶é—´**ï¼šAPI å¹³å‡å“åº”æ—¶é—´ < 100ms
- **å¹¶å‘å¤„ç†**ï¼šæ”¯æŒ 10,000+ QPS
- **æ•°æ®åº“æŸ¥è¯¢**ï¼šå•æ¬¡æŸ¥è¯¢ < 50ms
- **WebSocket**ï¼šæ”¯æŒ 10,000+ å¹¶å‘è¿æ¥
- **å†…å­˜å ç”¨**ï¼šå•å®ä¾‹ < 500MB

## ğŸš€ Go è¯­è¨€å¹¶å‘ä¼˜åŒ–

### 1. åç¨‹æ± ï¼ˆWorker Poolï¼‰æ¨¡å¼

**æ‰¹é‡å•†å“å¯¼å…¥ç¤ºä¾‹ï¼š**

```go
func BatchCreateProducts(products []models.Product) error {
    const batchSize = 100
    const workerCount = 5
    
    batches := make(chan []models.Product, len(products)/batchSize+1)
    results := make(chan error, len(products)/batchSize+1)
    
    // å¯åŠ¨ worker åç¨‹æ± 
    var wg sync.WaitGroup
    for i := 0; i < workerCount; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for batch := range batches {
                err := database.DB.CreateInBatches(batch, batchSize).Error
                results <- err
            }
        }()
    }
    
    // åˆ†æ‰¹å‘é€ä»»åŠ¡
    for i := 0; i < len(products); i += batchSize {
        end := i + batchSize
        if end > len(products) {
            end = len(products)
        }
        batches <- products[i:end]
    }
    close(batches)
    
    wg.Wait()
    close(results)
    
    return nil
}
```

**æ€§èƒ½æå‡ï¼š**
- å•çº¿ç¨‹ï¼š1000 å•†å“ ~10s
- åç¨‹æ± ï¼š1000 å•†å“ ~2s
- **æå‡ 5 å€**

### 2. åº“å­˜æ›´æ–°å¹¶å‘æ§åˆ¶

ä½¿ç”¨æ‚²è§‚é”é˜²æ­¢è¶…å–ï¼š

```go
func updateStock(productID uint, quantity int) error {
    return database.Transaction(func(tx *gorm.DB) error {
        var product models.Product
        
        // FOR UPDATE æ‚²è§‚é”
        if err := tx.Clauses(gorm.Locking{Strength: "UPDATE"}).
            First(&product, productID).Error; err != nil {
            return err
        }
        
        newStock := product.Stock + quantity
        if newStock < 0 {
            return errors.New("åº“å­˜ä¸è¶³")
        }
        
        return tx.Model(&product).Update("stock", newStock).Error
    })
}
```

### 3. Channel ä¼˜åŒ–

**å¸¦ç¼“å†² Channel å‡å°‘é˜»å¡ï¼š**

```go
// ä¸æ¨èï¼šæ— ç¼“å†²
jobs := make(chan Job)

// æ¨èï¼šå¸¦ç¼“å†²
jobs := make(chan Job, 256)
```

## ğŸ—„ï¸ æ•°æ®åº“ä¼˜åŒ–

### 1. ç´¢å¼•ä¼˜åŒ–

**å¿…é¡»åˆ›å»ºçš„ç´¢å¼•ï¼š**

```sql
-- å¤–é”®ç´¢å¼•
CREATE INDEX idx_products_category_id ON products(category_id);
CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_order_items_order_id ON order_items(order_id);

-- æŸ¥è¯¢æ¡ä»¶ç´¢å¼•
CREATE INDEX idx_products_status ON products(status);
CREATE INDEX idx_orders_status ON orders(status);

-- ç»„åˆç´¢å¼•
CREATE INDEX idx_products_category_status ON products(category_id, status);
CREATE INDEX idx_orders_user_status ON orders(user_id, status);

-- æ’åºç´¢å¼•
CREATE INDEX idx_orders_created_at ON orders(created_at DESC);
CREATE INDEX idx_products_sale_count ON products(sale_count DESC);
```

**ç´¢å¼•ä½¿ç”¨åˆ†æï¼š**

```sql
-- æŸ¥çœ‹æ‰§è¡Œè®¡åˆ’
EXPLAIN ANALYZE 
SELECT * FROM products 
WHERE category_id = 1 AND status = 'active' 
ORDER BY sale_count DESC 
LIMIT 20;
```

### 2. æŸ¥è¯¢ä¼˜åŒ–

**é¿å… N+1 æŸ¥è¯¢ï¼š**

```go
// âŒ ä¸æ¨èï¼šN+1 æŸ¥è¯¢
products, _ := productRepo.GetList()
for _, p := range products {
    category, _ := categoryRepo.GetByID(p.CategoryID)  // N æ¬¡æŸ¥è¯¢
}

// âœ… æ¨èï¼šä½¿ç”¨ Preload
db.Preload("Category").Find(&products)
```

**ä½¿ç”¨åˆ†é¡µï¼š**

```go
// è®¡ç®—æ€»æ•°å’Œåˆ†é¡µä¸€èµ·æ‰§è¡Œ
var products []models.Product
var total int64

query := db.Model(&models.Product{}).Where("status = ?", "active")
query.Count(&total)
query.Offset((page - 1) * pageSize).Limit(pageSize).Find(&products)
```

### 3. è¿æ¥æ± é…ç½®

```go
sqlDB, _ := db.DB()

// æœ€å¤§ç©ºé—²è¿æ¥æ•°
sqlDB.SetMaxIdleConns(50)

// æœ€å¤§æ‰“å¼€è¿æ¥æ•°
sqlDB.SetMaxOpenConns(200)

// è¿æ¥æœ€å¤§ç”Ÿå‘½å‘¨æœŸ
sqlDB.SetConnMaxLifetime(time.Hour)

// è¿æ¥æœ€å¤§ç©ºé—²æ—¶é—´
sqlDB.SetConnMaxIdleTime(10 * time.Minute)
```

**æ¨èé…ç½®ï¼š**
- å°å‹åº”ç”¨ï¼š10 ç©ºé—² / 50 æœ€å¤§
- ä¸­å‹åº”ç”¨ï¼š50 ç©ºé—² / 200 æœ€å¤§
- å¤§å‹åº”ç”¨ï¼š100 ç©ºé—² / 500 æœ€å¤§

### 4. æ‰¹é‡æ“ä½œ

```go
// âŒ ä¸æ¨èï¼šé€æ¡æ’å…¥
for _, product := range products {
    db.Create(&product)
}

// âœ… æ¨èï¼šæ‰¹é‡æ’å…¥
db.CreateInBatches(products, 100)
```

## ğŸ’¾ Redis ç¼“å­˜ä¼˜åŒ–

### 1. ç¼“å­˜ç­–ç•¥

**çƒ­ç‚¹æ•°æ®ç¼“å­˜ï¼š**

```go
func GetProductByID(id uint) (*models.Product, error) {
    ctx := context.Background()
    cacheKey := fmt.Sprintf("product:%d", id)
    
    // 1. å°è¯•ä»ç¼“å­˜è·å–
    cached, err := database.RedisClient.Get(ctx, cacheKey).Result()
    if err == nil {
        var product models.Product
        json.Unmarshal([]byte(cached), &product)
        return &product, nil
    }
    
    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    var product models.Product
    if err := database.DB.First(&product, id).Error; err != nil {
        return nil, err
    }
    
    // 3. å¼‚æ­¥å†™å…¥ç¼“å­˜
    go func() {
        data, _ := json.Marshal(product)
        database.RedisClient.Set(ctx, cacheKey, data, 1*time.Hour)
    }()
    
    return &product, nil
}
```

**ç¼“å­˜è¿‡æœŸæ—¶é—´å»ºè®®ï¼š**
- ç”¨æˆ·ä¿¡æ¯ï¼š7 å¤©
- å•†å“è¯¦æƒ…ï¼š1 å°æ—¶
- åˆ†ç±»åˆ—è¡¨ï¼š24 å°æ—¶
- çƒ­é—¨æ’è¡Œï¼š5 åˆ†é’Ÿ

### 2. ç¼“å­˜ç©¿é€é˜²æŠ¤

**ä½¿ç”¨ç©ºå€¼ç¼“å­˜ï¼š**

```go
// æŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®æ—¶ï¼Œç¼“å­˜ç©ºå€¼
if errors.Is(err, gorm.ErrRecordNotFound) {
    database.RedisClient.Set(ctx, cacheKey, "null", 5*time.Minute)
    return nil, err
}
```

### 3. ç¼“å­˜é›ªå´©é˜²æŠ¤

**æ·»åŠ éšæœºè¿‡æœŸæ—¶é—´ï¼š**

```go
// é¿å…å¤§é‡ç¼“å­˜åŒæ—¶è¿‡æœŸ
expireTime := 1*time.Hour + time.Duration(rand.Intn(300))*time.Second
database.RedisClient.Set(ctx, cacheKey, data, expireTime)
```

### 4. é™æµå®ç°

**æ»‘åŠ¨çª—å£é™æµï¼š**

```go
func RateLimitMiddleware(limit int, window time.Duration) gin.HandlerFunc {
    return func(c *gin.Context) {
        clientIP := c.ClientIP()
        key := fmt.Sprintf("rate_limit:%s", clientIP)
        
        ctx := context.Background()
        now := time.Now().Unix()
        windowStart := now - int64(window.Seconds())
        
        pipe := database.RedisClient.Pipeline()
        pipe.ZRemRangeByScore(ctx, key, "0", fmt.Sprintf("%d", windowStart))
        pipe.ZAdd(ctx, key, redis.Z{Score: float64(now), Member: fmt.Sprintf("%d", now)})
        pipe.ZCard(ctx, key)
        pipe.Expire(ctx, key, window)
        
        cmds, _ := pipe.Exec(ctx)
        count := cmds[2].(*redis.IntCmd).Val()
        
        if int(count) > limit {
            c.AbortWithStatusJSON(429, gin.H{"error": "è¯·æ±‚è¿‡äºé¢‘ç¹"})
            return
        }
        
        c.Next()
    }
}
```

## ğŸ”Œ WebSocket ä¼˜åŒ–

### 1. è¿æ¥æ± ç®¡ç†

```go
type Hub struct {
    clients     map[*Client]bool
    userClients map[uint]*Client
    broadcast   chan []byte
    register    chan *Client
    unregister  chan *Client
    mu          sync.RWMutex
}

// ä½¿ç”¨è¯»å†™é”å‡å°‘ç«äº‰
func (h *Hub) SendToUser(userID uint, msg *Message) bool {
    h.mu.RLock()
    client, exists := h.userClients[userID]
    h.mu.RUnlock()
    
    if !exists {
        return false
    }
    
    select {
    case client.send <- data:
        return true
    default:
        return false
    }
}
```

### 2. å¿ƒè·³æ£€æµ‹

```go
const (
    pongWait   = 60 * time.Second
    pingPeriod = (pongWait * 9) / 10
)

// å®šæ—¶å‘é€ ping
ticker := time.NewTicker(pingPeriod)
defer ticker.Stop()

for {
    select {
    case <-ticker.C:
        if err := conn.WriteMessage(websocket.PingMessage, nil); err != nil {
            return
        }
    }
}
```

### 3. æ¶ˆæ¯å‹ç¼©

```go
upgrader := websocket.Upgrader{
    EnableCompression: true,  // å¯ç”¨å‹ç¼©
    ReadBufferSize:    4096,
    WriteBufferSize:   4096,
}
```

## ğŸ—ï¸ æ¶æ„ä¼˜åŒ–

### 1. è¯»å†™åˆ†ç¦»

```go
// ä¸»åº“ï¼ˆå†™å…¥ï¼‰
dbMaster, _ := gorm.Open(postgres.Open(masterDSN))

// ä»åº“ï¼ˆè¯»å–ï¼‰
dbSlave, _ := gorm.Open(postgres.Open(slaveDSN))

// ä½¿ç”¨ GORM æ’ä»¶å®ç°è¯»å†™åˆ†ç¦»
db.Use(dbresolver.Register(dbresolver.Config{
    Sources:  []gorm.Dialector{postgres.Open(masterDSN)},
    Replicas: []gorm.Dialector{postgres.Open(slave1DSN), postgres.Open(slave2DSN)},
    Policy:   dbresolver.RandomPolicy{},
}))
```

### 2. åˆ†åº“åˆ†è¡¨

**æŒ‰ç”¨æˆ· ID åˆ†è¡¨ï¼š**

```go
func GetTableName(userID uint) string {
    tableIndex := userID % 10
    return fmt.Sprintf("orders_%d", tableIndex)
}
```

### 3. å¼‚æ­¥å¤„ç†

**è€—æ—¶ä»»åŠ¡å¼‚æ­¥åŒ–ï¼š**

```go
// è®¢å•åˆ›å»ºåå¼‚æ­¥å‘é€é€šçŸ¥
go func() {
    sendOrderNotification(order.UserID, order.ID)
    updateUserStatistics(order.UserID)
}()
```

## ğŸ“Š æ€§èƒ½ç›‘æ§

### 1. å…³é”®æŒ‡æ ‡

```go
import "github.com/prometheus/client_golang/prometheus"

var (
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request latencies in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )
)
```

### 2. æ…¢æŸ¥è¯¢æ—¥å¿—

```go
// GORM æ…¢æŸ¥è¯¢æ—¥å¿—
db.Logger = logger.New(
    log.New(os.Stdout, "\r\n", log.LstdFlags),
    logger.Config{
        SlowThreshold: 200 * time.Millisecond,  // æ…¢æŸ¥è¯¢é˜ˆå€¼
        LogLevel:      logger.Warn,
    },
)
```

## ğŸ§ª æ€§èƒ½æµ‹è¯•

### 1. åŸºå‡†æµ‹è¯•

```go
func BenchmarkGetProductList(b *testing.B) {
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        productService.GetProductList(&ProductListRequest{
            Page:     1,
            PageSize: 20,
        })
    }
}
```

### 2. å‹åŠ›æµ‹è¯•

ä½¿ç”¨ Apache Benchï¼š

```bash
# 1000 å¹¶å‘ï¼Œ100000 è¯·æ±‚
ab -n 100000 -c 1000 http://localhost:8080/api/v1/products
```

ä½¿ç”¨ wrkï¼š

```bash
# 100 è¿æ¥ï¼ŒæŒç»­ 30 ç§’
wrk -t12 -c100 -d30s http://localhost:8080/api/v1/products
```

## ğŸ“ˆ ä¼˜åŒ–æ•ˆæœ

| ä¼˜åŒ–é¡¹ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|--------|--------|--------|------|
| å•†å“åˆ—è¡¨æŸ¥è¯¢ | 200ms | 50ms | 4x |
| æ‰¹é‡å¯¼å…¥ 1000 å•†å“ | 10s | 2s | 5x |
| å¹¶å‘åº“å­˜æ›´æ–° | 500 QPS | 5000 QPS | 10x |
| WebSocket è¿æ¥æ•° | 1000 | 10000 | 10x |
| å†…å­˜å ç”¨ | 800MB | 300MB | 2.6x |

## âœ… ä¼˜åŒ–æ£€æŸ¥æ¸…å•

- [ ] æ•°æ®åº“ç´¢å¼•å·²ä¼˜åŒ–
- [ ] æŸ¥è¯¢ä½¿ç”¨äº† Preload é¿å… N+1
- [ ] å¯ç”¨äº† Redis ç¼“å­˜
- [ ] å®ç°äº†é™æµä¿æŠ¤
- [ ] æ‰¹é‡æ“ä½œä½¿ç”¨åç¨‹æ± 
- [ ] æ•°æ®åº“è¿æ¥æ± å·²é…ç½®
- [ ] å®ç°äº†æ…¢æŸ¥è¯¢ç›‘æ§
- [ ] é™æ€èµ„æºå¯ç”¨ CDN
- [ ] å¼€å¯äº† GZIP å‹ç¼©
- [ ] é…ç½®äº†æ€§èƒ½ç›‘æ§

---

æŒç»­ä¼˜åŒ–ï¼Œè¿½æ±‚æè‡´æ€§èƒ½ï¼ğŸš€
